{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try out different time series classification algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from train import Dataset\n",
    "from param import *\n",
    "\n",
    "datalist = ParamDir().data_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = datalist[2]\n",
    "dataset = Dataset(data_dir, 1.0, False)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = dataset.load_all_data(10, .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(a):\n",
    "    seg_ind = []\n",
    "    for i in range(len(a)-1):\n",
    "        if a[i] != a[i+1]:\n",
    "            seg_ind.append(i+1)\n",
    "    return seg_ind\n",
    "\n",
    "\n",
    "# ---- train set\n",
    "segment_ind = segment(y_train)\n",
    "\n",
    "y_new = np.append(y_train[0], y_train[segment_ind])\n",
    "\n",
    "X_seg = np.split(X_train, segment_ind)\n",
    "max_len = max([len(X) for X in X_seg])\n",
    "n_neurons = X_seg[0].shape[1]\n",
    "X_seg_new, y_new_train = [], []\n",
    "for _id, X in enumerate(X_seg):\n",
    "    if len(X) > 3: # the instance time points need to be more than 3 bins\n",
    "        y_new_train.append(str(y_new[_id]))\n",
    "        # X_seg_new.append(X) # unequal length\n",
    "        X_seg_new.append(np.vstack((X, np.zeros((max_len - len(X), n_neurons))))) # set to equal length with zeros\n",
    "y_new_train = np.array(y_new_train)\n",
    "\n",
    "# filter the neuron: delete the neurons where the activity is zero across instances\n",
    "neurons_to_use = np.vstack(X_seg_new).sum(axis=0)>0\n",
    "X_seg_new = [X[:, neurons_to_use ] for X in X_seg_new]\n",
    "\n",
    "X_new_train = pd.DataFrame([[pd.Series(i) for i in X.T] for X in X_seg_new])\n",
    "\n",
    "# ---- test set\n",
    "segment_ind = segment(y_test)\n",
    "\n",
    "y_new = np.append(y_test[0], y_test[segment_ind])\n",
    "\n",
    "X_seg = np.split(X_test, segment_ind)\n",
    "X_seg_new, y_new_test = [], []\n",
    "for _id, X in enumerate(X_seg):\n",
    "    if (len(X) <= max_len) and (len(X) > 3):\n",
    "        y_new_test.append(str(y_new[_id]))\n",
    "        # X_seg_new.append(X) # unequal length\n",
    "        X_seg_new.append(np.vstack((X, np.zeros((max_len - len(X), n_neurons))))) # set to equal length with zeros\n",
    "\n",
    "# filter the neuron: delete the neurons where the activity is zero across instances\n",
    "X_seg_new = [X[:, neurons_to_use ] for X in X_seg_new]\n",
    "\n",
    "X_new_test = pd.DataFrame([[pd.Series(i) for i in X.T] for X in X_seg_new])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with Unequal Length Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sktime.registry import all_estimators\n",
    "\n",
    "# # search for all classifiers which can handle unequal length data. This may give some\n",
    "# # UserWarnings if soft dependencies are not installed.\n",
    "# all_estimators(\n",
    "#     filter_tags={\"capability:unequal_length\": True}, estimator_types=\"classifier\"\n",
    "# )\n",
    "\n",
    "from sktime.classification.feature_based import RandomIntervalClassifier\n",
    "from sktime.transformations.panel.padder import PaddingTransformer\n",
    "\n",
    "padded_clf = PaddingTransformer() * RandomIntervalClassifier(n_intervals=4)\n",
    "padded_clf.fit(X_new_train, y_new_train)\n",
    "y_pred = padded_clf.predict(X_new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3076923076923077"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_new_test == y_pred)/len(y_new_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equal Length"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsTimeSeriesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "knn = KNeighborsTimeSeriesClassifier(n_neighbors=5)\n",
    "param_grid = {\"n_neighbors\": [1, 5], \"distance\": [\"euclidean\", \"dtw\"]}\n",
    "parameter_tuning_method = GridSearchCV(knn, param_grid, cv=KFold(n_splits=4))\n",
    "parameter_tuning_method.fit(X_new_train, y_new_train)\n",
    "y_pred = parameter_tuning_method.predict(X_new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38461538461538464"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_new_test == y_pred)/len(y_new_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RocketClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "\n",
    "rocket = RocketClassifier(num_kernels=2000)\n",
    "rocket.fit(X_new_train, y_new_train)\n",
    "y_pred = rocket.predict(X_new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6153846153846154"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_new_test == y_pred)/len(y_new_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HIVECOTEV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.hybrid import HIVECOTEV2\n",
    "\n",
    "hc2 = HIVECOTEV2(time_limit_in_minutes=0.2)\n",
    "hc2.fit(X_new_train, y_new_train)\n",
    "y_pred = hc2.predict(X_new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38461538461538464"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_new_test == y_pred)/len(y_new_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
